{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft margin SVM\n",
    "Soft margin SVM is a branch of SVM (Support Vector Machines) that allows the model to make some level of misclassifications as to make the decision boundary (SOFTER)\n",
    "\n",
    "Specifically, it aims to solve the following dual problem \n",
    "\n",
    "$$\n",
    "max \\space \\sum_{i}\\alpha_i - \\frac{1}{2}\\sum_i \\sum_j y^{(i)}y^{(j)}a_ia_j<x^{(i)}, x^{(j)}> \\\\\n",
    "s.t. \\space C \\ge \\alpha_i \\ge 0 , \\sum_i y^{(i)}\\alpha_i = 0\n",
    "$$\n",
    "\n",
    "With the following KKT conditions\n",
    "\n",
    "$$\n",
    "a_i = 0 \\Rightarrow y^{(i)}(w^Tx^{(i)}+b) \\ge 1 \\\\ \n",
    "a_i = C \\Rightarrow y^{(i)}(w^Tx^{(i)}+b) \\le 1 \\\\ \n",
    "C \\ge a_i \\ge 0 \\Rightarrow y^{(i)}(w^Tx^{(i)}+b) = 1\n",
    "$$\n",
    "\n",
    "Along side with kernel trick, SMO is one of the powerful tools that can do so. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Values\n",
    "- **point** corresponds to the training data $x_i$\n",
    "- **target** corresponds to the training outputs $y_i$\n",
    "- **C** is inversely proportional to the amount of mistakes we can afford. This depends on the scale of the problem. Mostly itâ€™s set from $.01 \\to100$\n",
    "- **tol** is the amount of tolerance we will have for the KKT conditions.\n",
    "- **prog_margin** is the padding we will employ for the calculation of $L$ and $H$ as to not make them equal. This will also serve as our margin in determining whether the two langrange multiplier has made any positive progress.\n",
    "- **clip_padding** is the padding we will apply on the constraint $C \\ge a_i \\ge 0$ where we wil clip $a_i$ to either $C$ or $0$ if itâ€™s within that padding\n",
    "\n",
    "â˜ðŸ» tol, prog_margin and clip_padding are mostly set to $1e^-3$ to $1e^-5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#np.random.seed(690420)\n",
    "\n",
    "M: int = 100\n",
    "D: int = 2\n",
    "point = np.random.normal(size=(M, D), loc=0, scale=10).astype(np.float64)\n",
    "target = np.random.choice([-1, 1], size=(M), replace=True)\n",
    "c: np.float64 = 100\n",
    "tol: np.float64 = 0\n",
    "prog_margin: np.float64 = 0\n",
    "clip_padding: np.float64 = 0\n",
    "max_ch: int = 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Function\n",
    "Function responsible for the kernel trick\n",
    "\n",
    "For gaussian Kernels we use the following \n",
    "$$\n",
    "K(x ,z ) = exp(-\\frac{||x-z||^2}{2\\sigma})\n",
    "$$\n",
    "\n",
    "This can be sped up from the fact that $||x-z||^2 = x * x - 2x*z + z *z $\n",
    "\n",
    "We can cache the dot product of vector to itself. We can also store the dot product of every 2 possible pair! but this may take a lot of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_kernels(size: int):\n",
    "    cache = np.zeros(shape=(size, size), dtype=np.float64)\n",
    "\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            cache[i, j] = kernel_gaussian(point[i], point[j])\n",
    "\n",
    "    return cache\n",
    "\n",
    "def kernel_gaussian(x: np.float32, z: np.array, sigma=1) -> float:\n",
    "    return np.exp((-(np.dot(z, z) - 2*np.dot(x, z) + np.dot(x, x))/(2 * sigma ** 2)))\n",
    "\n",
    "kernel_g_cache: np.float64 = initialize_kernels(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_svm_err(x: int, alphs: np.float64, err_cache: np.float64, b: np.float64) -> np.float64:\n",
    "    fx: np.float64 = obj_x(point[x], alphs, b, cache_val=x)\n",
    "    err_cache[x] = fx - target[x]\n",
    "    return err_cache[x]     \n",
    "\n",
    "def obj_x(val: np.float64, alphs: np.float64, b: np.float64, cache_val: int = -1) -> np.float64:\n",
    "    fx: np.float64 = b\n",
    "    alphs_zero: np.float64 = np.where(alphs != 0)[0]\n",
    "    \n",
    "    for i in alphs_zero:\n",
    "        K = kernel_g_cache[i, cache_val] if cache_val > -1 else kernel_gaussian(point[i], val)\n",
    "        fx += alphs[i] * target[i] * K\n",
    "        \n",
    "    return fx\n",
    "\n",
    "def accuracy(alphs: np.float64, b: np.float64) -> np.float64:\n",
    "    correct: float = 0.0\n",
    "\n",
    "    for i in range(M):\n",
    "        fx: np.float64 = obj_x(point[i], alphs, b, cache_val=i)\n",
    "        correct += (target[i]*fx > 0)\n",
    "    \n",
    "    return correct / M\n",
    "\n",
    "def predict(alphs: np.float64, b: np.float64, x: np.float64 = point, new: bool = False) -> np.float64:\n",
    "    res: np.float64 = np.zeros(shape=(len(x)), dtype=np.float64)\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        fx: np.float64 = obj_x(x[i], alphs, b, cache_val=(-1 if new else i))\n",
    "        res[i] = fx\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Function\n",
    "Lastly the function that takes a coordinate ascent step given the two multipliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_step(i1: int, i2: int, alphs: np.float64, non_bound_alphs: np.int64, err_cache: np.float64, B: np.float64, log: bool=False) -> bool:\n",
    "    #print(f\"Taking step for {i1} and {i2}\")\n",
    "    if (i1 == i2):\n",
    "        #print(\"Positions equal\")\n",
    "        return 0\n",
    "    \n",
    "    non_bound: bool = alphs[i1] != 0 and alphs[i1] != c\n",
    "    b: np.float64 = B[0]\n",
    "\n",
    "    E1: np.float64 = err_cache[i1] if non_bound else compute_svm_err(i1, alphs, err_cache, b)\n",
    "    E2: np.float64 = err_cache[i2] \n",
    "    y1: int = target[i1]\n",
    "    y2: int = target[i2]\n",
    "    alph1: np.float64 = alphs[i1]\n",
    "    alph2: np.float64 = alphs[i2]\n",
    "    s: int = y1 * y2\n",
    "\n",
    "    # Computation for L and H\n",
    "    if (y1 == y2):\n",
    "        L: np.float64 = max(0, alph1 + alph2 - c)\n",
    "        H: np.float64 = min(c, alph1 + alph2)\n",
    "    else:\n",
    "        L: np.float64 = max(0, alph2 - alph1)\n",
    "        H: np.float64 = min(c, c + alph2 - alph1)\n",
    "\n",
    "    if (L == H):\n",
    "        #print(\"L and H equal\")\n",
    "        return 0\n",
    "    \n",
    "    K11: np.float64 = kernel_g_cache[i1, i1]\n",
    "    K22: np.float64 = kernel_g_cache[i2, i2]\n",
    "    K12: np.float64 = kernel_g_cache[i1, i2]\n",
    "    eta: np.float64 = K11 + K22 - 2*K12\n",
    "\n",
    "    if (eta > 0):\n",
    "        alph2_new: np.float64 = (alph2) + (y2*(E1 - E2)/eta)\n",
    "        if (alph2_new <= L):\n",
    "            alph2_new = L\n",
    "        elif (alph2_new >= H):\n",
    "            alph2_new = H\n",
    "    else:\n",
    "        v1: np.float64 = E1 - alph1*y1*K11 - alph2*y2*K12\n",
    "        v2: np.float64 = E2 - alph1*y1*K12 - alph2*y2*K22\n",
    "        zeta: np.float64 = alph1*y1 + alph2*y2\n",
    "        Lobj: np.float64 = L*(1-s) + zeta*s*L*K11 - (.05*(L**2)*(K11 + K22)) - (zeta - s*L)*s*L*K12 + (v1 - v2)*y2*L\n",
    "        Hobj: np.float64 = H*(1-s) + zeta*s*H*K11 - (.05*(H**2)*(K11 + K22)) - (zeta - s*H)*s*H*K12 + (v1 - v2)*y2*H\n",
    "\n",
    "        if (Lobj < Hobj - prog_margin):\n",
    "            alph2_new: np.float64 = L\n",
    "        elif (Lobj > Hobj + prog_margin):\n",
    "            alph2_new: np.float64 = H    \n",
    "        else:\n",
    "            alph2_new: np.float64 = alph2\n",
    "\n",
    "    # clip\n",
    "    if (alph2_new < clip_padding):\n",
    "        alph2_new = 0\n",
    "    elif (alph2_new > c - clip_padding):\n",
    "        alph2_new = c\n",
    "        \n",
    "    if (abs(alph2_new - alph2) < (prog_margin * (alph2_new + alph2 + prog_margin))):\n",
    "        #print(\"Bad progress\")\n",
    "        return 0\n",
    "    \n",
    "    alph1_new: np.float64 = alph1 + (s*(alph2 - alph2_new))\n",
    "\n",
    "    # update tresholds\n",
    "    b1: np.float64 = b - E1 - y1*K11*(alph1_new - alph1) - y2*K12*(alph2_new - alph2)\n",
    "    b2: np.float64 = b - E2 - y1*K12*(alph1_new - alph1) - y2*K22*(alph2_new - alph2)\n",
    "    \n",
    "    if (alph1_new < c and alph1_new > 0):\n",
    "        B[0] = b1\n",
    "    elif (alph2_new < c and alph2_new > 0):\n",
    "        B[0] = b2\n",
    "    else:\n",
    "        B[0] = (b1 + b2)/2\n",
    "\n",
    "    # update err_cache\n",
    "    err_cache[i1], err_cache[i2] = 0, 0\n",
    "    for i in non_bound_alphs:\n",
    "        if (i == i1 or i == i2):\n",
    "            continue\n",
    "        \n",
    "        K1k: np.float64 = kernel_g_cache[i, i1]\n",
    "        K2k: np.float64 = kernel_g_cache[i, i2]\n",
    "\n",
    "        err_cache[i] += y1*K1k*(alph1_new - alph1) + y2*K2k*(alph2_new - alph2) + B[0] - b\n",
    "    \n",
    "    # update alphs\n",
    "    alphs[i1], alphs[i2] = alph1_new, alph2_new\n",
    "    \n",
    "    if (log):\n",
    "        print(f\"======= Step successful for {i1} and {i2} =======\")\n",
    "        print(f\"a1: {alph1} -> {alph1_new} | a2: {alph2} -> {alph2_new}\")\n",
    "        print(f\"b: {b} -> {B[0]}\")\n",
    "        print(f\"err_cache: {err_cache}\")\n",
    "        print(\"==================================================\")\n",
    "\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Alpha Function\n",
    "The second function which is responsible for checking the first langrange multiplier that is chosen and responsible for picking the next langrange multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def examine_a(i2: int, alphs: np.array, non_bound: bool, non_bound_alphs: np.int64, err_cache: np.array, B: np.float64) -> bool:\n",
    "    non_b_len: int = len(non_bound_alphs)\n",
    "    b: np.float64 = B[0]\n",
    "    E2: np.float64 = err_cache[i2] if non_bound else compute_svm_err(i2, alphs, err_cache, b)\n",
    "    r2: np.float64 = E2 * target[i2]\n",
    "    alph2: np.float64 = alphs[i2]\n",
    "\n",
    "    if ((r2 < -tol and alph2 < c) or (r2 > tol and alph2 > 0)):\n",
    "        #print(\"choosing second multipier\")\n",
    "        if (non_b_len > 1):\n",
    "            # Second heuristic using optimal err for step estimation\n",
    "            positive: bool = (err_cache[i2] >= 0)\n",
    "            i1: int = i2\n",
    "\n",
    "            for i in non_bound_alphs:\n",
    "                if (i == i2):\n",
    "                    continue\n",
    "\n",
    "                if (i1 == i2):\n",
    "                    i1 = i\n",
    "                elif (positive and err_cache[i] < err_cache[i1]):\n",
    "                    i1 = i\n",
    "                elif (not positive and err_cache[i] > err_cache[i1]):\n",
    "                    i1 = i\n",
    "\n",
    "            if (take_step(i1, i2, alphs, non_bound_alphs, err_cache, B)):\n",
    "                return 1\n",
    "\n",
    "        # take non-bound alps\n",
    "        if non_b_len > 0:\n",
    "            start: int = np.random.randint(size=(1), low=0, high=non_b_len)[0]\n",
    "            for i in range(non_b_len):\n",
    "                pos: int = (start + i)%non_b_len\n",
    "                if (take_step(non_bound_alphs[pos], i2, alphs, non_bound_alphs, err_cache, B)):\n",
    "                    return 1\n",
    "        \n",
    "        # loop through entire training set\n",
    "        start: int = np.random.randint(size=(1), low=0, high=M)[0]\n",
    "        for i in range(M):\n",
    "            if (take_step((start + i)%M, i2, alphs, non_bound_alphs, err_cache, B)):\n",
    "                return 1\n",
    "    \n",
    "    #print(\"already satisfy kkt conditions\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Function\n",
    "The train function which is responsible for picking the first langrange multiplier from a set of langrange multipliers. It is also responsible for initializing the important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smo_train() -> dict:\n",
    "    alphs: np.float64 = np.zeros(shape=(M), dtype=np.float64)\n",
    "    err_cache: np.float64 = np.zeros(shape=(M), dtype=np.float64)\n",
    "    B: np.float64 = np.array([0.], dtype=np.float64)\n",
    "\n",
    "    examine_all: bool = True\n",
    "    num_changed: int = 0\n",
    "    total_iter: int = 0\n",
    "\n",
    "    while num_changed > 0 or examine_all:\n",
    "        #print(\"choosing first multiplier\")\n",
    "        if total_iter >= max_ch:\n",
    "            break\n",
    "\n",
    "        num_changed = 0 \n",
    "        non_bound_alphs = np.where((alphs != 0) & (alphs != c))[0]\n",
    "\n",
    "        if examine_all:\n",
    "            for i in range(M):\n",
    "                num_changed += examine_a(i, alphs, False, non_bound_alphs, err_cache, B)\n",
    "        else:\n",
    "            for i in non_bound_alphs:\n",
    "                num_changed += examine_a(i, alphs, True, non_bound_alphs, err_cache, B)\n",
    "\n",
    "        if examine_all:\n",
    "            examine_all = False\n",
    "        elif num_changed == 0:\n",
    "            examine_all = True\n",
    "\n",
    "        total_iter += 1\n",
    "        print(\"Total iterations: \", total_iter)\n",
    "\n",
    "    #print(err_cache)\n",
    "    return {\"alphs\": alphs, \"err_cache\": err_cache, \"b\": B[0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "You can test the result here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nres = smo_train()\\nprint(accuracy(res['alphs'], res['b']))\\n\""
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "x = [(0.1+ (i * 0.1)) for i in range(1, 10)]\n",
    "y = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    c = x[i]\n",
    "    res = smo_train()\n",
    "    y.append(accuracy(res[\"alphs\"], res[\"b\"]))\n",
    "    \n",
    "plt.xlabel(\"c\")\n",
    "plt.ylabel(\"average distance\")\n",
    "plt.scatter(x, y)\n",
    "'''\n",
    "'''\n",
    "res = smo_train()\n",
    "print(accuracy(res['alphs'], res['b']))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEMO\n",
    "This Demo only works in 2 Dimensions, hence the number of parameters are at most 2\n",
    "Also, this overwrites the global variables above because the format of the code above is not object oriented (for note taking purposes)\n",
    "\n",
    "n = number of points per classification (i.e. M/2)\n",
    "\n",
    "You can treat the code below as a separate code, it's just created for visualization\n",
    "(I'm just hella tired of refactoring lol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iterations:  1\n",
      "Total iterations:  2\n",
      "Total iterations:  3\n",
      "Total iterations:  4\n",
      "Total iterations:  5\n",
      "Total iterations:  6\n",
      "Total iterations:  7\n",
      "Total iterations:  8\n",
      "Total iterations:  9\n",
      "Total iterations:  10\n",
      "Total iterations:  11\n",
      "Total iterations:  12\n",
      "Total iterations:  13\n",
      "Total iterations:  14\n",
      "Total iterations:  15\n",
      "Total iterations:  16\n",
      "Total iterations:  17\n",
      "Total iterations:  18\n",
      "Total iterations:  19\n",
      "Total iterations:  20\n",
      "Total iterations:  21\n",
      "Total iterations:  22\n",
      "Total iterations:  23\n",
      "Total iterations:  24\n",
      "Total iterations:  25\n",
      "Total iterations:  26\n",
      "Total iterations:  27\n",
      "Total iterations:  28\n",
      "Total iterations:  29\n",
      "Total iterations:  30\n",
      "Total iterations:  31\n",
      "Total iterations:  32\n",
      "Total iterations:  33\n",
      "Total iterations:  34\n",
      "Total iterations:  35\n",
      "Total iterations:  36\n",
      "Total iterations:  37\n",
      "Total iterations:  38\n",
      "Total iterations:  39\n",
      "Total iterations:  40\n",
      "Total iterations:  41\n",
      "Total iterations:  42\n",
      "Total iterations:  43\n",
      "Total iterations:  44\n",
      "Total iterations:  45\n",
      "Total iterations:  46\n",
      "Total iterations:  47\n",
      "Total iterations:  48\n",
      "Total iterations:  49\n",
      "Total iterations:  50\n",
      "Total iterations:  51\n",
      "Total iterations:  52\n",
      "Total iterations:  53\n",
      "Total iterations:  54\n",
      "Total iterations:  55\n",
      "Total iterations:  56\n",
      "Total iterations:  57\n",
      "Total iterations:  58\n",
      "Total iterations:  59\n",
      "Total iterations:  60\n",
      "Total iterations:  61\n",
      "Total iterations:  62\n",
      "Total iterations:  63\n",
      "Total iterations:  64\n",
      "Total iterations:  65\n",
      "Total iterations:  66\n",
      "Total iterations:  67\n",
      "Total iterations:  68\n",
      "Total iterations:  69\n",
      "Total iterations:  70\n",
      "Total iterations:  71\n",
      "Total iterations:  72\n",
      "Total iterations:  73\n",
      "Total iterations:  74\n",
      "Total iterations:  75\n",
      "Total iterations:  76\n",
      "Total iterations:  77\n",
      "Total iterations:  78\n",
      "Total iterations:  79\n",
      "Total iterations:  80\n",
      "Total iterations:  81\n",
      "Total iterations:  82\n",
      "Total iterations:  83\n",
      "Total iterations:  84\n",
      "Total iterations:  85\n",
      "Total iterations:  86\n",
      "Total iterations:  87\n",
      "Total iterations:  88\n",
      "Total iterations:  89\n",
      "Total iterations:  90\n",
      "Total iterations:  91\n",
      "Total iterations:  92\n",
      "Total iterations:  93\n",
      "Total iterations:  94\n",
      "Total iterations:  95\n",
      "Total iterations:  96\n",
      "Total iterations:  97\n",
      "Total iterations:  98\n",
      "Total iterations:  99\n",
      "Total iterations:  100\n",
      "Total iterations:  101\n",
      "Total iterations:  102\n",
      "Total iterations:  103\n",
      "Total iterations:  104\n",
      "Total iterations:  105\n",
      "Total iterations:  106\n",
      "Total iterations:  107\n",
      "Total iterations:  108\n",
      "Total iterations:  109\n",
      "Total iterations:  110\n",
      "Total iterations:  111\n",
      "Total iterations:  112\n",
      "Total iterations:  113\n",
      "Total iterations:  114\n",
      "Total iterations:  115\n",
      "Total iterations:  116\n",
      "Total iterations:  117\n",
      "Total iterations:  118\n",
      "Total iterations:  119\n",
      "Total iterations:  120\n",
      "Total iterations:  121\n",
      "Total iterations:  122\n",
      "Total iterations:  123\n",
      "Total iterations:  124\n",
      "Total iterations:  125\n",
      "Total iterations:  126\n",
      "Total iterations:  127\n",
      "Total iterations:  128\n",
      "Total iterations:  129\n",
      "Total iterations:  130\n",
      "Total iterations:  131\n",
      "Total iterations:  132\n",
      "Total iterations:  133\n",
      "Total iterations:  134\n",
      "Total iterations:  135\n",
      "Total iterations:  136\n",
      "Total iterations:  137\n",
      "Total iterations:  138\n",
      "Total iterations:  139\n",
      "Total iterations:  140\n",
      "Total iterations:  141\n",
      "Total iterations:  142\n",
      "Total iterations:  143\n",
      "Total iterations:  144\n",
      "Total iterations:  145\n",
      "Total iterations:  146\n",
      "Total iterations:  147\n",
      "Total iterations:  148\n",
      "Total iterations:  149\n",
      "Total iterations:  150\n",
      "Total iterations:  151\n",
      "Total iterations:  152\n",
      "Total iterations:  153\n",
      "Total iterations:  154\n",
      "Total iterations:  155\n",
      "Total iterations:  156\n",
      "Total iterations:  157\n",
      "Total iterations:  158\n",
      "Total iterations:  159\n",
      "Total iterations:  160\n",
      "Total iterations:  161\n",
      "Total iterations:  162\n",
      "Total iterations:  163\n",
      "Total iterations:  164\n",
      "Total iterations:  165\n",
      "Total iterations:  166\n",
      "Total iterations:  167\n",
      "Total iterations:  168\n",
      "Total iterations:  169\n",
      "Total iterations:  170\n",
      "Total iterations:  171\n",
      "Total iterations:  172\n",
      "Total iterations:  173\n",
      "Total iterations:  174\n",
      "Total iterations:  175\n",
      "Total iterations:  176\n",
      "Total iterations:  177\n",
      "Total iterations:  178\n",
      "Total iterations:  179\n",
      "Total iterations:  180\n",
      "Total iterations:  181\n",
      "Total iterations:  182\n",
      "Total iterations:  183\n",
      "Total iterations:  184\n",
      "Total iterations:  185\n",
      "Total iterations:  186\n",
      "Total iterations:  187\n",
      "Total iterations:  188\n",
      "Total iterations:  189\n",
      "Total iterations:  190\n",
      "Total iterations:  191\n",
      "Total iterations:  192\n",
      "Total iterations:  193\n",
      "Total iterations:  194\n",
      "Total iterations:  195\n",
      "Total iterations:  196\n",
      "Total iterations:  197\n",
      "Total iterations:  198\n",
      "Total iterations:  199\n",
      "Total iterations:  200\n",
      "Total iterations:  201\n",
      "Total iterations:  202\n",
      "Total iterations:  203\n",
      "Total iterations:  204\n",
      "Total iterations:  205\n",
      "Total iterations:  206\n",
      "Total iterations:  207\n",
      "Total iterations:  208\n",
      "Total iterations:  209\n",
      "Total iterations:  210\n",
      "Total iterations:  211\n",
      "Total iterations:  212\n",
      "Total iterations:  213\n",
      "Total iterations:  214\n",
      "Total iterations:  215\n",
      "Total iterations:  216\n",
      "Total iterations:  217\n",
      "Total iterations:  218\n",
      "Total iterations:  219\n",
      "Total iterations:  220\n",
      "Total iterations:  221\n",
      "Total iterations:  222\n",
      "Total iterations:  223\n",
      "Total iterations:  224\n",
      "Total iterations:  225\n",
      "Total iterations:  226\n",
      "Total iterations:  227\n",
      "Total iterations:  228\n",
      "Total iterations:  229\n",
      "Total iterations:  230\n",
      "Total iterations:  231\n",
      "Total iterations:  232\n",
      "Total iterations:  233\n",
      "Total iterations:  234\n",
      "Total iterations:  235\n",
      "Total iterations:  236\n",
      "Total iterations:  237\n",
      "Total iterations:  238\n",
      "Total iterations:  239\n",
      "Total iterations:  240\n",
      "Total iterations:  241\n",
      "Total iterations:  242\n",
      "Total iterations:  243\n",
      "Total iterations:  244\n",
      "Total iterations:  245\n",
      "Total iterations:  246\n",
      "Total iterations:  247\n",
      "Total iterations:  248\n",
      "Total iterations:  249\n",
      "Total iterations:  250\n",
      "Total iterations:  251\n",
      "Total iterations:  252\n",
      "Total iterations:  253\n",
      "Total iterations:  254\n",
      "Total iterations:  255\n",
      "Total iterations:  256\n",
      "Total iterations:  257\n",
      "Total iterations:  258\n",
      "Total iterations:  259\n",
      "Total iterations:  260\n",
      "Total iterations:  261\n",
      "Total iterations:  262\n",
      "Total iterations:  263\n",
      "Total iterations:  264\n",
      "Total iterations:  265\n",
      "Total iterations:  266\n",
      "Total iterations:  267\n",
      "Total iterations:  268\n",
      "Total iterations:  269\n",
      "Total iterations:  270\n",
      "Total iterations:  271\n",
      "Total iterations:  272\n",
      "Total iterations:  273\n",
      "Total iterations:  274\n",
      "Total iterations:  275\n",
      "Total iterations:  276\n",
      "Total iterations:  277\n",
      "Total iterations:  278\n",
      "Total iterations:  279\n",
      "Total iterations:  280\n",
      "Total iterations:  281\n",
      "Total iterations:  282\n",
      "Total iterations:  283\n",
      "Total iterations:  284\n",
      "Total iterations:  285\n",
      "Total iterations:  286\n",
      "Total iterations:  287\n",
      "Total iterations:  288\n",
      "Total iterations:  289\n",
      "Total iterations:  290\n",
      "Total iterations:  291\n",
      "Total iterations:  292\n",
      "Total iterations:  293\n",
      "Total iterations:  294\n",
      "Total iterations:  295\n",
      "Total iterations:  296\n",
      "Total iterations:  297\n",
      "Total iterations:  298\n",
      "Total iterations:  299\n",
      "Total iterations:  300\n",
      "Total iterations:  301\n",
      "Total iterations:  302\n",
      "Total iterations:  303\n",
      "Total iterations:  304\n",
      "Total iterations:  305\n",
      "Total iterations:  306\n",
      "Total iterations:  307\n",
      "Total iterations:  308\n",
      "Total iterations:  309\n",
      "Total iterations:  310\n",
      "Total iterations:  311\n",
      "Total iterations:  312\n",
      "Total iterations:  313\n",
      "Total iterations:  314\n",
      "Total iterations:  315\n",
      "Total iterations:  316\n",
      "Total iterations:  317\n",
      "Total iterations:  318\n",
      "Total iterations:  319\n",
      "Total iterations:  320\n",
      "Total iterations:  321\n",
      "Total iterations:  322\n",
      "Total iterations:  323\n",
      "Total iterations:  324\n",
      "Total iterations:  325\n",
      "Total iterations:  326\n",
      "Total iterations:  327\n",
      "Total iterations:  328\n",
      "Total iterations:  329\n",
      "Total iterations:  330\n",
      "Total iterations:  331\n",
      "Total iterations:  332\n",
      "Total iterations:  333\n",
      "Total iterations:  334\n",
      "Total iterations:  335\n",
      "Total iterations:  336\n",
      "Total iterations:  337\n",
      "Total iterations:  338\n",
      "Total iterations:  339\n",
      "Total iterations:  340\n",
      "Total iterations:  341\n",
      "Total iterations:  342\n",
      "Total iterations:  343\n",
      "Total iterations:  344\n",
      "Total iterations:  345\n",
      "Total iterations:  346\n",
      "Total iterations:  347\n",
      "Total iterations:  348\n",
      "Total iterations:  349\n",
      "Total iterations:  350\n",
      "Total iterations:  351\n",
      "Total iterations:  352\n",
      "Total iterations:  353\n",
      "Total iterations:  354\n",
      "Total iterations:  355\n",
      "Total iterations:  356\n",
      "Total iterations:  357\n",
      "Total iterations:  358\n",
      "Total iterations:  359\n",
      "Total iterations:  360\n",
      "Total iterations:  361\n",
      "Total iterations:  362\n",
      "Total iterations:  363\n",
      "Total iterations:  364\n",
      "Total iterations:  365\n",
      "Total iterations:  366\n",
      "Total iterations:  367\n",
      "Total iterations:  368\n",
      "Total iterations:  369\n",
      "Total iterations:  370\n",
      "Total iterations:  371\n",
      "Total iterations:  372\n",
      "Total iterations:  373\n",
      "Total iterations:  374\n",
      "Total iterations:  375\n",
      "Total iterations:  376\n",
      "Total iterations:  377\n",
      "Total iterations:  378\n",
      "Total iterations:  379\n",
      "Total iterations:  380\n",
      "Total iterations:  381\n",
      "Total iterations:  382\n",
      "Total iterations:  383\n",
      "Total iterations:  384\n",
      "Total iterations:  385\n",
      "Total iterations:  386\n",
      "Total iterations:  387\n",
      "Total iterations:  388\n",
      "Total iterations:  389\n",
      "Total iterations:  390\n",
      "Total iterations:  391\n",
      "Total iterations:  392\n",
      "Total iterations:  393\n",
      "Total iterations:  394\n",
      "Total iterations:  395\n",
      "Total iterations:  396\n",
      "Total iterations:  397\n",
      "Total iterations:  398\n",
      "Total iterations:  399\n",
      "Total iterations:  400\n",
      "Total iterations:  401\n",
      "Total iterations:  402\n",
      "Total iterations:  403\n",
      "Total iterations:  404\n",
      "Total iterations:  405\n",
      "Total iterations:  406\n",
      "Total iterations:  407\n",
      "Total iterations:  408\n",
      "Total iterations:  409\n",
      "Total iterations:  410\n",
      "Total iterations:  411\n",
      "Total iterations:  412\n",
      "Total iterations:  413\n",
      "Total iterations:  414\n",
      "Total iterations:  415\n",
      "Total iterations:  416\n",
      "Total iterations:  417\n",
      "Total iterations:  418\n",
      "Total iterations:  419\n",
      "Total iterations:  420\n",
      "Total iterations:  421\n",
      "Total iterations:  422\n",
      "Total iterations:  423\n",
      "Total iterations:  424\n",
      "Total iterations:  425\n",
      "Total iterations:  426\n",
      "Total iterations:  427\n",
      "Total iterations:  428\n",
      "Total iterations:  429\n",
      "Total iterations:  430\n",
      "Total iterations:  431\n",
      "Total iterations:  432\n",
      "Total iterations:  433\n",
      "Total iterations:  434\n",
      "Total iterations:  435\n",
      "Total iterations:  436\n",
      "Total iterations:  437\n",
      "Total iterations:  438\n",
      "Total iterations:  439\n",
      "Total iterations:  440\n",
      "Total iterations:  441\n",
      "Total iterations:  442\n",
      "Total iterations:  443\n",
      "Total iterations:  444\n",
      "Total iterations:  445\n",
      "Total iterations:  446\n",
      "Total iterations:  447\n",
      "Total iterations:  448\n",
      "Total iterations:  449\n",
      "Total iterations:  450\n",
      "Total iterations:  451\n",
      "Total iterations:  452\n",
      "Total iterations:  453\n",
      "Total iterations:  454\n",
      "Total iterations:  455\n",
      "Total iterations:  456\n",
      "Total iterations:  457\n",
      "Total iterations:  458\n",
      "Total iterations:  459\n",
      "Total iterations:  460\n",
      "Total iterations:  461\n",
      "Total iterations:  462\n",
      "Total iterations:  463\n",
      "Total iterations:  464\n",
      "Total iterations:  465\n",
      "Total iterations:  466\n",
      "Total iterations:  467\n",
      "Total iterations:  468\n",
      "Total iterations:  469\n",
      "Total iterations:  470\n",
      "Total iterations:  471\n",
      "Total iterations:  472\n",
      "Total iterations:  473\n",
      "Total iterations:  474\n",
      "Total iterations:  475\n",
      "Total iterations:  476\n",
      "Total iterations:  477\n",
      "Total iterations:  478\n",
      "Total iterations:  479\n",
      "Total iterations:  480\n",
      "Total iterations:  481\n",
      "Total iterations:  482\n",
      "Total iterations:  483\n",
      "Total iterations:  484\n",
      "Total iterations:  485\n",
      "Total iterations:  486\n",
      "Total iterations:  487\n",
      "Total iterations:  488\n",
      "Total iterations:  489\n",
      "Total iterations:  490\n",
      "Total iterations:  491\n",
      "Total iterations:  492\n",
      "Total iterations:  493\n",
      "Total iterations:  494\n",
      "Total iterations:  495\n",
      "Total iterations:  496\n",
      "Total iterations:  497\n",
      "Total iterations:  498\n",
      "Total iterations:  499\n",
      "Total iterations:  500\n",
      "Total iterations:  501\n",
      "Total iterations:  502\n",
      "Total iterations:  503\n",
      "Total iterations:  504\n",
      "Total iterations:  505\n",
      "Total iterations:  506\n",
      "Total iterations:  507\n",
      "Total iterations:  508\n",
      "Total iterations:  509\n",
      "Total iterations:  510\n",
      "Total iterations:  511\n",
      "Total iterations:  512\n",
      "Total iterations:  513\n",
      "Total iterations:  514\n",
      "Total iterations:  515\n",
      "Total iterations:  516\n",
      "Total iterations:  517\n",
      "Total iterations:  518\n",
      "Total iterations:  519\n",
      "Total iterations:  520\n",
      "Total iterations:  521\n",
      "Total iterations:  522\n",
      "Total iterations:  523\n",
      "Total iterations:  524\n",
      "Total iterations:  525\n",
      "Total iterations:  526\n",
      "Total iterations:  527\n",
      "Total iterations:  528\n",
      "Total iterations:  529\n",
      "Total iterations:  530\n",
      "Total iterations:  531\n",
      "Total iterations:  532\n",
      "Total iterations:  533\n",
      "Total iterations:  534\n",
      "Total iterations:  535\n",
      "Total iterations:  536\n",
      "Total iterations:  537\n",
      "Total iterations:  538\n",
      "Total iterations:  539\n",
      "Total iterations:  540\n",
      "Total iterations:  541\n",
      "Total iterations:  542\n",
      "Total iterations:  543\n",
      "Total iterations:  544\n",
      "Total iterations:  545\n",
      "Total iterations:  546\n",
      "Total iterations:  547\n",
      "Total iterations:  548\n",
      "Total iterations:  549\n",
      "Total iterations:  550\n",
      "Total iterations:  551\n",
      "Total iterations:  552\n",
      "Total iterations:  553\n",
      "Total iterations:  554\n",
      "Total iterations:  555\n",
      "Total iterations:  556\n",
      "Total iterations:  557\n",
      "Total iterations:  558\n",
      "Total iterations:  559\n",
      "Total iterations:  560\n",
      "Total iterations:  561\n",
      "Total iterations:  562\n",
      "Total iterations:  563\n",
      "Total iterations:  564\n",
      "Total iterations:  565\n",
      "Total iterations:  566\n",
      "Total iterations:  567\n",
      "Total iterations:  568\n",
      "Total iterations:  569\n",
      "Total iterations:  570\n",
      "Total iterations:  571\n",
      "Total iterations:  572\n",
      "Total iterations:  573\n",
      "Total iterations:  574\n",
      "Total iterations:  575\n",
      "Total iterations:  576\n",
      "Total iterations:  577\n",
      "Total iterations:  578\n",
      "Total iterations:  579\n",
      "Total iterations:  580\n",
      "Total iterations:  581\n",
      "Total iterations:  582\n",
      "Total iterations:  583\n",
      "Total iterations:  584\n",
      "Total iterations:  585\n",
      "Total iterations:  586\n",
      "Total iterations:  587\n",
      "Total iterations:  588\n",
      "Total iterations:  589\n",
      "Total iterations:  590\n",
      "Total iterations:  591\n",
      "Total iterations:  592\n",
      "Total iterations:  593\n",
      "Total iterations:  594\n",
      "Total iterations:  595\n",
      "Total iterations:  596\n",
      "Total iterations:  597\n",
      "Total iterations:  598\n",
      "Total iterations:  599\n",
      "Total iterations:  600\n",
      "len:  200\n",
      "support vector: 9 / 200\n",
      "index = 32, alpha = 0.100, predict y=1.095\n",
      "index = 58, alpha = 0.410, predict y=1.000\n",
      "index = 84, alpha = 1.369, predict y=1.000\n",
      "index = 86, alpha = 1.493, predict y=1.000\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 111 is out of bounds for axis 0 with size 100",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, alpha \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malphs\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m alpha \u001b[38;5;241m>\u001b[39m sv_threshold:\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, alpha = \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m, predict y=\u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\\\n\u001b[1;32m---> 47\u001b[0m             \u001b[38;5;241m.\u001b[39mformat(idx, alpha, \u001b[43mtrain_y\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m))\n\u001b[0;32m     49\u001b[0m         sv_idx\u001b[38;5;241m.\u001b[39mappend(idx)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Threshold\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 111 is out of bounds for axis 0 with size 100"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "n = 100\n",
    "M = n*2     # Overwrites the above M to make this wor\n",
    "D = 2       # Ensures dimensions are 2\n",
    "\n",
    "def gen_circle(n, center_x=0, center_y=0, radius=1, label=0):\n",
    "    alpha = 2 * np.pi * np.random.rand(n)\n",
    "    r = radius * np.sqrt(np.random.rand(n))\n",
    "    x = r * np.cos(alpha) + center_x\n",
    "    y = r * np.sin(alpha) + center_y\n",
    "    label = np.ones(n) * label\n",
    "    return [x, y, label]\n",
    "\n",
    "C0 = gen_circle(n, center_x=1, center_y=1, radius=1.05, label=1)\n",
    "C1 = gen_circle(n, center_x=-1, center_y=-1, radius=1.05, label=-1)\n",
    "\n",
    "x0 = np.append(C0[0], C1[0])\n",
    "x1 = np.append(C0[1], C1[1])\n",
    "\n",
    "X = np.c_[x0, x1]\n",
    "Y = np.append(C0[2], C1[2])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_x = scaler.fit_transform(X)\n",
    "\n",
    "# Main function\n",
    "point = train_x\n",
    "target = Y\n",
    "kernel_g_cache = initialize_kernels(M) # Reinitializes the kernels above\n",
    "model = smo_train()\n",
    "\n",
    "# Prediction in vector\n",
    "train_y = predict(model['alphs'], model['b'], new=False)\n",
    "print('support vector: {} / {}'\\\n",
    "    .format(len(model['alphs'][model['alphs'] > 1e-5]), len(model['alphs'])))\n",
    "\n",
    "# Gathers the support vectors (non-zero alpha)\n",
    "sv_threshold = 0\n",
    "sv_idx = []\n",
    "for idx, alpha in enumerate(model['alphs']):\n",
    "    if alpha > sv_threshold:\n",
    "        print('index = {}, alpha = {:.3f}, predict y={:.3f}'\\\n",
    "            .format(idx, alpha, train_y[idx]))\n",
    "        \n",
    "        sv_idx.append(idx)\n",
    "\n",
    "# Threshold\n",
    "print(f'bias = {model[\"b\"]}')\n",
    "# Error rate\n",
    "train_y_sign = np.sign(train_y)\n",
    "error_rate = np.mean(train_y_sign != target)\n",
    "print('training data error rate = {:.2f}'.format(error_rate))\n",
    "\n",
    "# Draw the Plot\n",
    "plt.plot(C0[0], C0[1], 'o', markerfacecolor='r', markeredgecolor='None', alpha=0.55)\n",
    "plt.plot(C1[0], C1[1], 'o', markerfacecolor='b', markeredgecolor='None', alpha=0.55)\n",
    "\n",
    "resolution = 50\n",
    "dx = np.linspace(X[:, 0].min(), X[:, 0].max(), resolution)\n",
    "dy = np.linspace(X[:, 1].min(), X[:, 1].max(), resolution)\n",
    "dx, dy = np.meshgrid(dx, dy)\n",
    "plot_x = np.c_[dx.flatten(), dy.flatten()]\n",
    "\n",
    "transformed_plot_x = scaler.transform(plot_x)\n",
    "dz = predict(model['alphs'], model['b'], transformed_plot_x, True)\n",
    "dz = dz.reshape(dx.shape)\n",
    "\n",
    "plt.contour(dx, dy, dz, alpha=1, colors=('b', 'k', 'r'), \\\n",
    "            levels=(-1, 0, 1), linestyles = ('--', '-', '--'))\n",
    "\n",
    "label_cnt = 0\n",
    "for i in sv_idx:\n",
    "    if label_cnt == 0:\n",
    "        plt.scatter(X[i, 0], X[i, 1], marker='*', color='k', \\\n",
    "                    s=120, label='Support vector')\n",
    "        label_cnt += 1\n",
    "        continue\n",
    "\n",
    "    plt.scatter(X[i, 0], X[i, 1], marker='*', color='k', s=120)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.18769253  1.06943439  1.07407152  0.51408798  0.          4.36606805\n",
      "  3.25993356  0.59066836  1.0785893   0.52707946  0.90194392  0.94237848\n",
      "  1.10171915  1.07612638  1.07858932  1.08465017  2.5751695   0.28601538\n",
      "  0.          0.32333221  1.47677533  4.02023442  1.22359447  1.34382971\n",
      " 11.56448674  1.15566744  1.41272492  1.00374111  1.82447341  3.56103977\n",
      "  0.02120517  0.83821641  1.07882468  1.18213207  1.08201888  1.22190285\n",
      "  1.11577233  0.8924493   2.41637044  1.08062226  0.73007492  1.19970888\n",
      "  0.82461499  1.62775832  1.3012044   1.01298801  1.17766055  1.07961236\n",
      "  0.79169213  1.18457191  0.92168426  1.43207383  0.87062607  2.76275559\n",
      "  0.81888327  1.6229317   0.92141068  0.86910969  0.88036188  0.91790286\n",
      "  0.32495205  1.93098925  7.32253013  0.77454241  0.88040329  0.89373294\n",
      "  0.92145866  0.77799649  0.92852399  0.92600263  0.87190693  0.94234077\n",
      "  0.90562375  6.29608866  1.01190335  1.07560731  0.92141042  1.12884594\n",
      "  4.30194814  4.53042485  0.6958043   0.92251117  0.93142491  0.91701888\n",
      "  0.          0.92141068  0.70800732  0.8706264   0.91533578  0.92129009\n",
      "  1.2494777   1.4216155   1.13856416  1.8561235   1.15221996  0.92115777\n",
      "  0.92163919  5.49237522  0.92053286  0.92141064]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(model['alphs'])\n",
    "print(accuracy(model['alphs'], model['b']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
